{"cells":[{"metadata":{"id":"D8EF5E6B73B74D2A8838E782C37EBEE5","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"# 线性回归笔记"},{"metadata":{"id":"BEEE2690096948D885600B2AFC70CD2A","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"## 1、pytorch中的广播机制\n\npytorch中的广播机制和numpy中的广播机制一样, 因为都是数组的广播机制。\n\n### 核心\n如果相加的两个数组的shape不同, 就会触发广播机制, \n1)程序会自动执行操作使得A.shape==B.shape, \n2)对应位置进行相加,运算结果的shape是:A.shape和B.shape对应位置的最大值\n比如:A.shape=(1,9,4),B.shape=(15,1,4),那么A+B的shape是(15,9,4)\n\n两个维度不同的Tensor可以相乘, 示例："},{"metadata":{"id":"B1509B58A8324FD3825ABF9A11A552EB","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"a=tensor([0, 1, 2, 3, 4, 5])\na.shape=torch.Size([6])\na.ndim=1\nb=tensor([[ 0,  1,  2,  3,  4,  5],\n        [ 6,  7,  8,  9, 10, 11]])\nb.shape=torch.Size([2, 6])\nb.ndim=2\nres=tensor([[ 0,  1,  4,  9, 16, 25],\n        [ 0,  7, 16, 27, 40, 55]])\nres.shape=torch.Size([2, 6])\nres.ndim=2\n","name":"stdout"}],"source":"a = torch.arange(0, 6).reshape((6,))\nb = torch.arange(0, 12).reshape((2, 6))\n# a和b的ndim不同, 但是可以element-wise相乘, 因为用到了广播机制\nres = torch.mul(a, b)\nprint(f'a={a}\\na.shape={a.shape}\\na.ndim={a.ndim}')\nprint(f'b={b}\\nb.shape={b.shape}\\nb.ndim={b.ndim}')\nprint(f'res={res}\\nres.shape={res.shape}\\nres.ndim={res.ndim}')","execution_count":6},{"metadata":{"id":"3E940297B3234961894B7F0606A55B39","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"### 有两种情况能够进行广播\n1、A.ndim > B.ndim, 并且A.shape最后几个元素包含B.shape, 比如下面三种情况:\n\tA.shape=(2,3,4,5), B.shape=(3,4,5)\n\tA.shape=(2,3,4,5), B.shape=(4,5)\n\tA.shape=(2,3,4,5), B.shape=(5)\n2、A.ndim == B.ndim, 并且A.shape和B.shape对应位置的元素要么相同要么其中一个是1, 比如\n\tA.shape=(1,9,4), B.shape=(15,1,4)\n\tA.shape=(1,9,4), B.shape=(15,1,1)\n注意不要混淆ndim和shape这两个基本概念，基本上ndim=len(shape)"},{"metadata":{"id":"4C40E4C462E042798118595CC41E615D","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"#### A.ndim > B.ndim"},{"metadata":{"id":"B9F41CBF8C4D474B85675D8D1BA3C618","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"a (2, 2, 3, 4)\nb (3, 4)\na+b (2, 2, 3, 4)\n[[[[ True  True  True  True]\n   [ True  True  True  True]\n   [ True  True  True  True]]\n\n  [[ True  True  True  True]\n   [ True  True  True  True]\n   [ True  True  True  True]]]\n\n\n [[[ True  True  True  True]\n   [ True  True  True  True]\n   [ True  True  True  True]]\n\n  [[ True  True  True  True]\n   [ True  True  True  True]\n   [ True  True  True  True]]]]\n","name":"stdout"}],"source":"import numpy as np\na = np.arange(1, 49).reshape((2, 2, 3, 4))\nb = np.arange(1, 13).reshape((3, 4))\n# numpy会将b.shape调整至(2,2,3,4), 这一步相当于numpy自动实现np.tile(b,[2,2,1,1])\nres = a + b\nprint('a', a.shape)\nprint('b', b.shape)\nprint('a+b', res.shape)\nprint(a+b == a + np.tile(b, [2, 2, 1, 1]))\n","execution_count":11},{"metadata":{"id":"0E89E2EA783D403D8ACA5752AF23384C","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"#### A.ndim == B.ndim"},{"metadata":{"id":"04081F4630234A7599BFB66B584C6FDA","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"a (4, 3)\nb (4, 1)\na+b (4, 3)\n[[ True  True  True]\n [ True  True  True]\n [ True  True  True]\n [ True  True  True]]\n","name":"stdout"}],"source":"a = np.arange(12).reshape(4,3)\nb = np.arange(4).reshape(4,1)\n# numpy会将b.shape调整至(4,3), 这一步相当于numpy自动实现np.tile(b,[1,3])\nres = a + b\nprint('a', a.shape)\nprint('b', b.shape)\nprint('a+b', res.shape)\nprint((a+b == a + np.tile(b,[1,3])) )","execution_count":12},{"metadata":{"id":"304843C856DA4B39B23EE4151AE28C72","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"a (1, 9, 4)\nb (15, 1, 4)\na+b (15, 9, 4)\n[[[ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]]\n\n [[ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]]\n\n [[ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]]\n\n [[ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]]\n\n [[ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]]\n\n [[ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]]\n\n [[ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]]\n\n [[ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]]\n\n [[ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]]\n\n [[ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]]\n\n [[ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]]\n\n [[ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]]\n\n [[ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]]\n\n [[ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]]\n\n [[ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]\n  [ True  True  True  True]]]\n","name":"stdout"}],"source":"a = np.arange(1,37).reshape((1,9,4))\nb = np.arange(1,61).reshape((15,1,4))\nres = a + b\nprint('a', a.shape)\nprint('b', b.shape)\nprint('a+b', res.shape)\nq = np.tile(a,[15,1,1]) + np.tile(b,[1,9,1])\nprint(q == res)","execution_count":13},{"metadata":{"id":"7599674879B24C2F84B141B7E887B822","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"## 2、参数的形状与批量大小没有关系\n正是因为如此，对同一个模型，我们可以选择不同的批量大小。"},{"metadata":{"id":"164C17221C614A378F84F5FCC1CC5EC3","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"## 3、View()函数\n在torch.Tensor.view()下的一个函数，可以有tensor调用，也可以有variable调用。\n\n其作用在于返回和原tensor数据个数相同，但size不同的tensor\n\n【Numpy中的size是元素个数，但是在Pytorch中size等价为Numpy中的shape】\n\nview函数的-1参数的作用在于基于另一参数，自动计算该维度的大小"},{"metadata":{"id":"30C03A17B65148DD89F3E5242E871BA4","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tensor([0, 1, 2])\ntensor([[0],\n        [1],\n        [2]])\ntensor([[0],\n        [1],\n        [2]])\ntensor([0, 1, 2])\ntensor([0, 1, 2])\ntensor([[0],\n        [1],\n        [2]])\n","name":"stdout"}],"source":"import torch\nx = torch.arange(3)\ny1 = x.view(3, 1)\ny2 = x.view(y1.size())\ny3 = x.view(3)\ny4 = x.view(-1)\ny5 = x.view(-1,1)\nprint(x)\nprint(y1)\nprint(y2)\nprint(y3)\nprint(y4)\nprint(y5)","execution_count":19}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.3","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":0}